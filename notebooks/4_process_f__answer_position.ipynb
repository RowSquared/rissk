{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T23:03:35.127989Z",
     "start_time": "2023-08-16T23:03:34.990115Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.import_utils import *\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from src.feature_processing import *\n",
    "from src.item_processing import  *\n",
    "from src.utils.stats_utils import *\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path='../configuration', version_base='1.1'):\n",
    "    config = compose(config_name='main.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_class = ItemFeatureProcessing(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = features_class.df_item\n",
    "self = features_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T23:03:39.645724Z",
     "start_time": "2023-08-16T23:03:39.331960Z"
    }
   },
   "outputs": [],
   "source": [
    "pivot_table, index_col = self.get_clean_pivot_table('f__answer_position',remove_low_freq_col=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pivot_table.drop(columns = ['interview__id', 'roster_level', 'responsible']).columns:\n",
    "    data = pivot_table[~pd.isnull(pivot_table[col])].copy()\n",
    "    entropy_ = data.groupby('responsible')[col].apply(calculate_entropy)\n",
    "    #entropy_ = entropy_.reset_index()\n",
    "    #data[col+'_entropy'] = data['responsible'].map(entropy_[col])\n",
    "    entropy_.plot(kind='bar')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T23:03:43.356899Z",
     "start_time": "2023-08-16T23:03:42.923671Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in pivot_table.drop(columns = ['interview__id', 'roster_level', 'responsible']).columns:\n",
    "    data = pivot_table[~pd.isnull(pivot_table[col])].copy()\n",
    "    entropy_ = data.groupby('responsible')[col].apply(calculate_entropy)\n",
    "    entropy_ = entropy_.reset_index()\n",
    "    pivot_table[col+'_entropy'] = pivot_table['responsible'].map(entropy_.set_index('responsible')[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T23:04:54.105932Z",
     "start_time": "2023-08-16T23:04:53.862700Z"
    }
   },
   "outputs": [],
   "source": [
    "entropy_columns = [col for col in pivot_table.columns if 'entropy' in col]\n",
    "pivot_table['entropy__answer_position'] = pivot_table[entropy_columns].fillna(0).mean(1)\n",
    "entropy_ = pivot_table.groupby('responsible')['entropy__answer_position'].mean()\n",
    "entropy_.plot(kind='bar')\n",
    "plt.title('entropy__answer_position')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy.stats import entropy\n",
    "# from scipy.stats import entropy\n",
    "# \n",
    "# def jensen_shannon_divergence(p, q):\n",
    "#     \"\"\"Compute the Jensen-Shannon divergence between two distributions.\"\"\"\n",
    "#     m = 0.5 * (p + q)\n",
    "#     return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)\n",
    "# # Sample data\n",
    "# \n",
    "# \n",
    "# def compute_kl_divergence(df, col='f__answer_position'):\n",
    "#     responsibles = df['responsible'].unique()\n",
    "#     kl_divergence = {}\n",
    "# \n",
    "#     # Compute the overall distribution for each unique value\n",
    "#     overall_distribution = df[col].value_counts(normalize=True).sort_index()\n",
    "# \n",
    "#     for resp in responsibles:\n",
    "#         # Distribution for the current responsible\n",
    "#         resp_distribution = df[df['responsible'] == resp][col].value_counts(normalize=True).sort_index()\n",
    "# \n",
    "#         # Combine distributions to ensure they cover the same range of values\n",
    "#         combined = pd.concat([resp_distribution, overall_distribution], axis=1, sort=True).fillna(0)\n",
    "#         resp_distribution = combined.iloc[:, 0]\n",
    "#         overall_distribution = combined.iloc[:, 1]\n",
    "# \n",
    "#         # Compute KL divergence\n",
    "#         kl = jensen_shannon_divergence(resp_distribution, overall_distribution)\n",
    "#         kl_divergence[resp] = kl\n",
    "# \n",
    "#     return kl_divergence\n",
    "# data = pivot_table[~pd.isnull(pivot_table[col])].copy()\n",
    "# kl_results = compute_kl_divergence(data, col)\n",
    "# print(kl_results)\n",
    "# data['kl'] = data['responsible'].replace(kl_results)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(column):\n",
    "    # Value counts normalizes the counts to get probabilities\n",
    "    prob_distribution = column.value_counts(normalize=True).values\n",
    "    return entropy(prob_distribution)* len(column)\n",
    "\n",
    "# Group by responsible and calculate entropy\n",
    "entropy = data.groupby('responsible')[col].apply(calculate_entropy)\n",
    "#entropy = entropy.reset_index()\n",
    "#data['entropy'] = data['responsible'].map(entropy.set_index('responsible')[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "data = pivot_table[~pd.isnull(pivot_table[col])].copy()\n",
    "prob_distribution = data[col].value_counts(normalize=True)\n",
    "entropy(prob_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.groupby('responsible')['entropy'].max()\n",
    "#x = x.reset_index()\n",
    "x.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlss",
   "language": "python",
   "name": "mlss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
