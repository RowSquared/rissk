{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:35:31.745745Z",
     "start_time": "2023-08-04T07:35:28.566498Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from utils.import_utils import *\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "with initialize(config_path='../configuration', version_base='1.1'):\n",
    "    config = compose(config_name='main.yaml')\n",
    "survey_list = SurveyManager(config)\n",
    "dfs_paradata, dfs_questionnaires, dfs_microdata = survey_list.get_dataframes(reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Microdata based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:09.428457Z",
     "start_time": "2023-08-04T07:44:09.321076Z"
    }
   },
   "outputs": [],
   "source": [
    "#group_columns = [col for col in dfs_microdata.columns if col.endswith(\"__id\")]+['survey_name', 'survey_version']\n",
    "item_level_columns = ['interview__id', 'variable_name', 'roster_level']\n",
    "\n",
    "feat_item = dfs_microdata[item_level_columns+['value', 'type', 'is_integer', 'n_answers', 'answer_sequence']].copy()\n",
    "\n",
    "feat_item['value'].fillna('', inplace=True)\n",
    "\n",
    "text_question_mask = (feat_item['type'] == 'TextQuestion')\n",
    "numeric_question_mask = (feat_item['type'] == 'NumericQuestion') & (feat_item['value'] != '')\n",
    "decimal_question_mask = (feat_item['is_integer'] == False) & (feat_item['value'] != '')\n",
    "\n",
    "# TODO, should we limit to active questions, interviewer only, etc?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:10.485192Z",
     "start_time": "2023-08-04T07:44:10.439412Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__string_length, length of string answer, if TextQuestions, empty if not\n",
    "feat_item['f__string_length'] = pd.NA\n",
    "feat_item.loc[text_question_mask, 'f__string_length'] = feat_item.loc[text_question_mask, 'value'].str.len()\n",
    "feat_item['f__string_length']=feat_item['f__string_length'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:11.730798Z",
     "start_time": "2023-08-04T07:44:11.703579Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__numeric_response, response, if NumericQuestions, empty if not\n",
    "feat_item['f__numeric_response'] = np.nan\n",
    "feat_item.loc[numeric_question_mask, 'f__numeric_response'] = feat_item[numeric_question_mask]['value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:12.687553Z",
     "start_time": "2023-08-04T07:44:12.664545Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__first_digit, first digit of the response if numeric question, empty if not\n",
    "feat_item['f__first_digit'] = pd.NA\n",
    "feat_item.loc[numeric_question_mask, 'f__first_digit'] = feat_item.loc[numeric_question_mask, 'value'].astype(str).str[0].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:13.785942Z",
     "start_time": "2023-08-04T07:44:13.746699Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__last_digit, modulus of 10 of the response if numeric question, empty if not\n",
    "feat_item['f__last_digit'] = pd.NA\n",
    "feat_item.loc[numeric_question_mask, 'f__last_digit'] = feat_item.loc[numeric_question_mask, 'value'].astype(int) % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:14.583788Z",
     "start_time": "2023-08-04T07:44:14.545788Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__first_decimal, first decimal digit if numeric question, empty if not\n",
    "feat_item['f__first_decimal'] = pd.NA\n",
    "values = feat_item.loc[decimal_question_mask, 'value'].astype(float)\n",
    "feat_item.loc[decimal_question_mask, 'f__first_decimal'] = np.floor(values * 10) % 10\n",
    "feat_item['f__first_decimal']=feat_item['f__first_decimal'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:16.029172Z",
     "start_time": "2023-08-04T07:44:15.549761Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__rel_answer_position, relative position of the selected answer\n",
    "feat_item['f__answer_position'] = pd.NA\n",
    "single_question_mask = (feat_item['type']=='SingleQuestion') & (feat_item['n_answers'] > 2 ) # only questions with more than two answers\n",
    "feat_item.loc[single_question_mask, 'f__answer_position'] = feat_item.loc[single_question_mask].apply(lambda row: round(row['answer_sequence'].index(row['value'])/(row['n_answers']-1),3) if (row['value'] in row['answer_sequence']) and pd.notnull(row['value']) else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:16.854041Z",
     "start_time": "2023-08-04T07:44:16.798590Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__Latitude, f__Longitude, f__Accuracy\n",
    "gps_mask = feat_item['type'] == 'GpsCoordinateQuestion'\n",
    "gps_df = feat_item.loc[gps_mask, 'value'].str.split(',', expand=True)\n",
    "gps_df.columns = ['gps__Latitude', 'gps__Longitude', 'gps__Accuracy', 'gps__Altitude', 'gps__Timestamp']\n",
    "feat_item.loc[gps_mask, 'f__Latitude'] = pd.to_numeric(gps_df['gps__Latitude'], errors='coerce')\n",
    "feat_item.loc[gps_mask, 'f__Longitude'] = pd.to_numeric(gps_df['gps__Longitude'], errors='coerce')\n",
    "feat_item.loc[gps_mask, 'f__Accuracy'] = pd.to_numeric(gps_df['gps__Accuracy'], errors='coerce')\n",
    "feat_item.drop([col for col in feat_item.columns if col.startswith('gps__')], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:44:19.686437Z",
     "start_time": "2023-08-04T07:44:19.655727Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# f__answers_selected, number of answers selected in a multi-answer or list question\n",
    "# f__share_selected, share between answers selected, and available answers (only for unlinked questions)\n",
    "\n",
    "def count_elements_or_nan(val): # Function to calculate number of elements in a list or return nan\n",
    "    if isinstance(val, list):\n",
    "        return len(val)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "multi_list_mask = feat_item['type'].isin(['MultyOptionsQuestion', 'TextListQuestion'])\n",
    "feat_item.loc[multi_list_mask,'f__answers_selected'] = feat_item.loc[multi_list_mask, 'value'].apply(count_elements_or_nan)\n",
    "feat_item['f__share_selected'] = round(feat_item['f__answers_selected'] / feat_item['n_answers'],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Paradata based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T07:52:00.919203Z",
     "start_time": "2023-08-04T07:52:00.261943Z"
    }
   },
   "outputs": [],
   "source": [
    "# dfs_paradata modifications, move to import-utils?\n",
    "\n",
    "# streamline missing (empty, NaN) to '', important to identify duplicates in terms of roster below\n",
    "dfs_paradata.fillna('', inplace=True)\n",
    "\n",
    "# interviewing, True prior to Supervisor/HQ interaction, else False\n",
    "events_split = ['RejectedBySupervisor', 'OpenedBySupervisor', 'OpenedByHQ', 'RejectedByHQ']\n",
    "grouped = dfs_paradata.groupby('interview__id')\n",
    "dfs_paradata['interviewing'] = False\n",
    "for _, group_df in grouped:\n",
    "    matching_events = group_df['event'].isin(events_split)\n",
    "    min_index = group_df.index.min()\n",
    "    if matching_events.any():\n",
    "        max_index = matching_events.idxmax() - 1\n",
    "    else:\n",
    "        max_index = group_df.index.max()\n",
    "    dfs_paradata.loc[min_index:max_index, 'interviewing'] = True\n",
    "# TODO: @GABRIELE, please update above, fix to interviewing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T07:56:25.165254Z",
     "start_time": "2023-07-27T07:56:24.706633Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_para_active, active events, prior rejection/review events, for questions with scope interviewer\n",
    "\n",
    "active_events = ['InterviewCreated', 'AnswerSet', 'Resumed', 'AnswerRemoved', 'CommentSet', 'Restarted']\n",
    "\n",
    "# keep active events, prior rejection/review events, for questions with scope interviewer\n",
    "active_mask = (dfs_paradata['event'].isin(active_events)) & \\\n",
    "              (dfs_paradata['interviewing']) & \\\n",
    "              (dfs_paradata['question_scope'] == 0) & \\\n",
    "              (dfs_paradata['role']==1)\n",
    "\n",
    "\n",
    "vars_needed = ['interview__id', 'order', 'event', 'responsible', 'role', 'tz_offset', 'param', 'answer','roster_level', 'datetime_utc', 'variable_name', 'question_sequence', 'question_scope', 'type', 'question_type',  'survey_name', 'survey_version', 'interviewing', 'yes_no_view']\n",
    "\n",
    "df_para_active = dfs_paradata.loc[active_mask,vars_needed].copy().sort_values(['interview__id', 'order']).reset_index()\n",
    "# TODO @Gabriele, reset the index after appending in para\n",
    "\n",
    "# only keep events done by interview (in most cases this should be all, after above filters, just in case supervisor or HQ answered something while interviewer answered on web mode)\n",
    "#df_active = df_active[df_active['role']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T09:20:50.484200Z",
     "start_time": "2023-07-27T09:20:49.678635Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__duration_answer, total time spent to record answers, i.e. sum of all time-intervals from active events ending with the item being AnswerSet or AnswerRemoved\n",
    "# f__duration_comment, total time spent to comment, i.e. sum of all time-intervals from active events ending with the item being CommentSet\n",
    "# f__time_reset\n",
    "df_time = df_para_active.copy()\n",
    "\n",
    "# calculate time difference in seconds\n",
    "df_time['time_difference'] = df_time.groupby('interview__id')['datetime_utc'].diff()\n",
    "df_time['time_difference'] = df_time['time_difference'].dt.total_seconds()\n",
    "df_time['f__time_changed'] = np.where(df_time['time_difference'] < -120, df_time['time_difference'], np.nan)\n",
    "df_time.loc[df_time['time_difference'] < 0, 'time_difference'] = pd.NA\n",
    "# time for answers/comments\n",
    "df_time['f__duration_answer'] = df_time.loc[df_time['event'].isin(['AnswerSet', 'AnswerRemoved']), 'time_difference']\n",
    "df_time['f__duration_comment'] = df_time.loc[df_time['event']=='CommentSet', 'time_difference']\n",
    "\n",
    "# summarize on item level\n",
    "df_time = df_time.groupby(item_level_columns).agg(\n",
    "    f__duration_answer=('f__duration_answer', 'sum'),\n",
    "    f__duration_comment=('f__duration_comment', 'sum'),\n",
    "    f__time_changed=('f__time_changed', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "# drop rows without VariableName\n",
    "df_time = df_time[df_time['variable_name']!='']\n",
    "\n",
    "# merge into feat_item\n",
    "feat_item = feat_item.merge(df_time, on=item_level_columns, how='outer', indicator=True)\n",
    "# TODO: Gabriele, integrate this cell, sets negative numbers to NA and generates new feature\n",
    "# TODO: I think we should we use TZ adjusted time instead of utc, no?\n",
    "\n",
    "# Find rows from df_time that didn't have a match\n",
    "#unmatched_rows = df_time[~df_time.isin(merged_df)]\n",
    "#merged_df = merged_df[(merged_df['value']!='') & (merged_df['f__duration_answer'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T13:51:05.420828Z",
     "start_time": "2023-07-26T13:51:04.974357Z"
    }
   },
   "outputs": [],
   "source": [
    "# last AnswerSet on item-level\n",
    "df_last = df_para_active[df_para_active['event']=='AnswerSet'].groupby(item_level_columns).last()\n",
    "df_last = df_last.sort_values(['interview__id', 'order']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T13:51:06.095645Z",
     "start_time": "2023-07-26T13:51:06.024975Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__previous_question, f__previous_answer, f__previous_roster for previous answer set\n",
    "df_last['f__previous_question'] = df_last.groupby('interview__id')['variable_name'].shift(fill_value='')\n",
    "df_last['f__previous_answer'] = df_last.groupby('interview__id')['answer'].shift(fill_value='')\n",
    "df_last['f__previous_roster'] = df_last.groupby('interview__id')['roster_level'].shift(fill_value='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T13:51:06.865638Z",
     "start_time": "2023-07-26T13:51:06.816914Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__half_hour, half-hour interval of last time answered\n",
    "df_last['f__half_hour'] = df_last['datetime_utc'].dt.hour + df_last['datetime_utc'].dt.round('30min').dt.minute / 60\n",
    "\n",
    "# f__in_working_hours, indication if f__half_hour is within working hours\n",
    "half_hour_counts = df_last['f__half_hour'].value_counts().sort_index()\n",
    "\n",
    "threshold = half_hour_counts.median()*0.33  # approach 1: interval < 1/3 of the median count of answers set\n",
    "working_hours_1 = half_hour_counts[half_hour_counts >= threshold].index.tolist()\n",
    "\n",
    "cumulative_share = (half_hour_counts.sort_values().cumsum()/half_hour_counts.sum()).sort_index()\n",
    "working_hours_2 = half_hour_counts[cumulative_share >= 0.05].index.tolist() # approach 2: the least frequent intervals with total of 5% of answers set\n",
    "\n",
    "df_last['f__in_working_hours'] = df_last['f__half_hour'].isin(working_hours_2)\n",
    "\n",
    "# f__half_hour_prob_norm\n",
    "df_last['half_hour_probability'] = df_last['f__half_hour'].map(df_last['f__half_hour'].value_counts(normalize=True))\n",
    "max_probability = df_last['half_hour_probability'].max()\n",
    "df_last['f__half_hour_prob_norm'] =  ((max_probability - df_last['half_hour_probability']) / max_probability)\n",
    "\n",
    "# to be merged into df_item\n",
    "\n",
    "# TODO: add timezone offset, think about if we want to do this by day of the week or by calendar day?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T13:52:14.587983Z",
     "start_time": "2023-07-26T13:52:14.322364Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__sequence_jump, Difference between actual answer sequence and question sequence in the questionnaire, in difference to previous question\n",
    "df_last['answer_sequence'] = df_last.groupby('interview__id').cumcount() + 1\n",
    "df_last['diff'] = df_last['question_sequence'] - df_last['answer_sequence']\n",
    "df_last['f__sequence_jump'] = df_last.groupby('interview__id')['diff'].diff()\n",
    "\n",
    "merge_columns = item_level_columns + [c for c in df_last.columns if c.startswith('f__')]\n",
    "feat_item = feat_item.merge(df_last[merge_columns], on=item_level_columns, how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T20:11:51.147508Z",
     "start_time": "2023-07-21T20:11:50.027247Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__answer_changed\n",
    "\n",
    "df_changed_temp = df_para_active[df_para_active['event'] == 'AnswerSet'].copy()\n",
    "df_changed_temp['f__answer_changed'] = False\n",
    "\n",
    "# list and multi-select questions (without yes_no_mode)\n",
    "list_mask = (df_changed_temp['type'] == 'TextListQuestion')\n",
    "multi_mask = (df_changed_temp['yes_no_view'] == False)\n",
    "df_changed_temp['answer_list'] = pd.NA\n",
    "df_changed_temp.loc[list_mask, 'answer_list'] = df_changed_temp.loc[list_mask,'answer'].str.split('|')\n",
    "df_changed_temp.loc[multi_mask, 'answer_list'] = df_changed_temp.loc[multi_mask,'answer'].str.split(', |\\\\|')\n",
    "df_changed_temp['prev_answer_list'] = df_changed_temp.groupby(item_level_columns)['answer_list'].shift()\n",
    "answers_mask = df_changed_temp['prev_answer_list'].notna()\n",
    "df_changed_temp.loc[answers_mask,'f__answer_changed'] = df_changed_temp.loc[answers_mask].apply(lambda row: not set(row['prev_answer_list']).issubset(set(row['answer_list'])), axis=1)\n",
    "\n",
    "# single answer question\n",
    "df_changed_temp['prev_answer'] = df_changed_temp.groupby(item_level_columns)['answer'].shift()\n",
    "single_answer_mask = (~df_changed_temp['type'].isin(['MultyOptionsQuestion', 'TextListQuestion'])) & \\\n",
    "                     (df_changed_temp['prev_answer'].notna()) & \\\n",
    "                     (df_changed_temp['answer'] != df_changed_temp['prev_answer'])\n",
    "df_changed_temp.loc[single_answer_mask, 'f__answer_changed'] = True\n",
    "\n",
    "# yes_no_view questions\n",
    "yesno_mask = (df_changed_temp['yes_no_view'] == True)\n",
    "df_filtered = df_changed_temp[yesno_mask].copy()\n",
    "df_filtered[['yes_list', 'no_list']] = df_filtered['answer'].str.split('|', expand=True)\n",
    "df_filtered['yes_list'] = df_filtered['yes_list'].str.split(', ').apply(lambda x: [] if x == [''] or x is None else x)\n",
    "df_filtered['no_list'] = df_filtered['no_list'].str.split(', ').apply(lambda x: [] if x == [''] or x is None else x)\n",
    "df_filtered['prev_yes_list'] = df_filtered.groupby(item_level_columns)['yes_list'].shift(fill_value=[])\n",
    "df_filtered['prev_no_list'] = df_filtered.groupby(item_level_columns)['no_list'].shift(fill_value=[])\n",
    "df_changed_temp.loc[yesno_mask,'f__answer_changed'] = df_filtered.apply(lambda row: not set(row['prev_yes_list']).issubset(set(row['yes_list'])), axis=1)\n",
    "df_changed_temp.loc[yesno_mask,'f__answer_changed'] = df_filtered.apply(lambda row: not set(row['prev_no_list']).issubset(set(row['no_list'])), axis=1)\n",
    "\n",
    "# count on item level\n",
    "df_changed_temp = df_changed_temp.groupby(item_level_columns)['f__answer_changed'].sum().reset_index()\n",
    "\n",
    "# TODO: merge into df_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Other paradata based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T12:50:27.858730Z",
     "start_time": "2023-07-21T12:50:27.801772Z"
    }
   },
   "outputs": [],
   "source": [
    "splits = df_para_multi['answer'].str.split(', |\\\\|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:58:50.615481Z",
     "start_time": "2023-07-18T12:58:50.577268Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__answer_removed, answers removed (by interviewer, or by system as a result of interviewer action).\n",
    "removed_mask = (dfs_paradata['interviewing']) & \\\n",
    "               (dfs_paradata['interviewing']) & \\\n",
    "               (dfs_paradata['event']=='AnswerRemoved')\n",
    "df_item_removed = dfs_paradata[removed_mask]\n",
    "\n",
    "df_item_removed = df_item_removed.groupby(item_level_columns).agg(\n",
    "    f__answer_removed=('order', 'count'),\n",
    "    ).reset_index()\n",
    "# to be merged into df_item\n",
    "\n",
    "df_unit_removed = df_item_removed.groupby('interview__id').agg(\n",
    "    f__answer_removed=('f__answer_removed', 'sum'),\n",
    ")\n",
    "# to be merged into df_unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:58:51.777824Z",
     "start_time": "2023-07-18T12:58:51.732657Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__comments_set, f_comment_length\n",
    "comment_mask = (dfs_paradata['event']=='CommentSet') & \\\n",
    "               (dfs_paradata['role']==1) & \\\n",
    "               (dfs_paradata['interviewing'])\n",
    "df_item_comment = dfs_paradata[comment_mask].copy()\n",
    "df_item_comment['f__comment_length'] = df_item_comment['answer'].str.len()\n",
    "df_item_comment = df_item_comment.groupby(item_level_columns).agg(\n",
    "    f__comments_set=('order', 'count'),\n",
    "    f__comment_length=('f__comment_length', 'sum'),\n",
    "    ).reset_index()\n",
    "# to be merged into df_item\n",
    "\n",
    "df_unit_comment = df_item_comment.groupby('interview__id').agg(\n",
    "    f__comments_set=('f__comments_set', 'sum'),\n",
    "    f__comment_length=('f__comment_length', 'sum')\n",
    ").reset_index()\n",
    "# to be merged into df_unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T08:12:57.641200Z",
     "start_time": "2023-07-19T08:12:57.457814Z"
    }
   },
   "outputs": [],
   "source": [
    "# f__pause_count, f__pause_duration, f__pause_list\n",
    "df_paused_temp =  dfs_paradata[['interview__id', 'order', 'event', 'datetime_utc', 'interviewing']].copy()\n",
    "df_paused_temp['prev_event'] = df_paused_temp.groupby('interview__id')['event'].shift(fill_value='')\n",
    "df_paused_temp['prev_datetime'] = df_paused_temp.groupby('interview__id')['datetime_utc'].shift()\n",
    "pause_mask = df_paused_temp['event'].isin(['Restarted', 'Resumed']) & \\\n",
    "             df_paused_temp['prev_event'].isin(['Paused']) & \\\n",
    "             (df_paused_temp['interviewing'])\n",
    "df_paused_temp = df_paused_temp.loc[pause_mask].copy()\n",
    "df_paused_temp['pause_duration'] = df_paused_temp['datetime_utc'] - df_paused_temp['prev_datetime']\n",
    "df_paused_temp['pause_seconds'] = df_paused_temp['pause_duration'].dt.total_seconds().astype('Int64')\n",
    "df_paused_temp = df_paused_temp.groupby('interview__id').agg({\n",
    "    'pause_seconds': ['count', 'sum', lambda x: x.tolist()]\n",
    "})\n",
    "\n",
    "df_paused_temp.columns = ['f_pause_count', 'f_pause_duration', 'f_pause_list']\n",
    "df_paused_temp = df_paused_temp.reset_index()\n",
    "\n",
    "# to be merged into df_unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T09:43:14.316682Z",
     "start_time": "2023-07-20T09:43:13.916073Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_mask = (dfs_paradata['interviewing']) & \\\n",
    "             (dfs_paradata['event'].isin(['AnswerSet','TranslationSwitched']))\n",
    "\n",
    "df_trans_temp =  dfs_paradata.loc[trans_mask,['interview__id', 'order', 'event', 'param']].copy().reset_index()\n",
    "df_trans_temp['seq'] = df_trans_temp.groupby('interview__id').cumcount() + 1\n",
    "\n",
    "# Define a function to calculate the relative positions\n",
    "def relative_translation_positions(group):\n",
    "    total_rows = len(group)\n",
    "    translation_position = group.loc[group['event'] == 'TranslationSwitched','seq']\n",
    "    relative_positions = [pos / total_rows for pos in translation_position]\n",
    "    return relative_positions\n",
    "\n",
    "# Group by 'interview__id' and apply the function\n",
    "df_trans_temp = df_trans_temp.groupby('interview__id').apply(relative_translation_positions).reset_index().rename(columns={0: 'f__translation_positions'})\n",
    "\n",
    "# to be merged into df_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TODO\n",
    "1. add timezone to hour of the day\n",
    "2. add index to paradata import utils\n",
    "3. redo interviewing column\n",
    "4. @Gabriele, after the refactor, roster_level seems empty and in column answer\n",
    "5. remove the answer changed from refactor\n",
    "6. @ Gabriele, I will need interview__errors in long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
