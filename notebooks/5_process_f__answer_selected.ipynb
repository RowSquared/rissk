{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "\n",
    "from src.item_processing import  *\n",
    "from src.utils.stats_utils import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path='../configuration', version_base='1.1'):\n",
    "    config = compose(config_name='main.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_class = ItemFeatureProcessing(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = features_class.df_item\n",
    "self = features_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Answer Selected ITEM Level Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot_table, index_col = self.get_clean_pivot_table('f__answer_selected',remove_low_freq_col=True)\n",
    "feature_name = 'f__answer_selected'\n",
    "score_name = self.rename_feature(feature_name)\n",
    "df = self.df_item[~pd.isnull(self.df_item[feature_name])].copy()\n",
    "# Select only those variables that have at least three distinct values and more than one hundred records\n",
    "valid_variables = self.filter_variable_name_by_frequency(df, feature_name, frequency=100, min_unique_values=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Identify anomalies in the percentage of selected answers and plot them. It Uses ECOD as we are interested in detecting unusual high or low number of item selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_name1 = score_name + '_lower'      \n",
    "score_name2 = score_name + '_upper'\n",
    "for var in valid_variables:\n",
    "    mask = (df['variable_name'] == var)\n",
    "    contamination = self.get_contamination_parameter(feature_name, method='medfilt', random_state=42)    \n",
    "    model = ECOD(contamination=0.11)\n",
    "    model.fit(df[mask][[feature_name]])\n",
    "\n",
    "\n",
    "    df.loc[mask, score_name] = model.predict(df[mask][[feature_name]])\n",
    "    \n",
    "    min_good_value = df[(df[score_name]==0) & mask][feature_name].min()\n",
    "    max_good_value = df[(df[score_name]==0) & mask][feature_name].max()\n",
    "    \n",
    "    df.loc[mask, score_name1] = 0 \n",
    "    df.loc[mask, score_name2] = 0     \n",
    "\n",
    "    df.loc[mask & (df[mask][feature_name] < min_good_value), score_name1] = 1 \n",
    "    df.loc[mask & (df[mask][feature_name] > max_good_value), score_name2] = 1 \n",
    "    \n",
    "    \n",
    "    bins = np.histogram_bin_edges(df[mask][feature_name], bins=48)\n",
    "    data_true = df[(df[score_name]==0) & mask][feature_name]\n",
    "    data_lower = df[(df[score_name1]==1) & mask][feature_name]\n",
    "    data_upper = df[(df[score_name2]==1) & mask][feature_name]\n",
    "    \n",
    "    plt.hist(data_true, bins=bins, alpha=0.5, color='blue', label='True')\n",
    "    plt.hist(data_lower, bins=bins, alpha=0.5, color='red', label='False')\n",
    "    plt.hist(data_upper, bins=bins, alpha=0.5, color='orange', label='False')\n",
    "    plt.title(var)\n",
    "    plt.show()\n",
    "    \n",
    "    df.drop(columns=[score_name], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plot the box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_range in range(0, len(valid_variables), 50):\n",
    "    variables = valid_variables[index_range:index_range+50]\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.boxplot(df[df['variable_name'].isin(variables)],x='variable_name', y=feature_name, hue=score_name1)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Answer Selected UNIT Level Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T00:15:33.184586Z",
     "start_time": "2023-08-27T00:15:32.953670Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.groupby(['interview__id']).agg({score_name1: 'mean', score_name2:'mean'})\n",
    "data = data.reset_index()\n",
    "data[score_name1].hist()\n",
    "plt.title(score_name1)\n",
    "plt.show()\n",
    "data[score_name2].hist()\n",
    "plt.title(score_name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T00:16:08.605609Z",
     "start_time": "2023-08-27T00:16:08.539117Z"
    }
   },
   "outputs": [],
   "source": [
    "total_unit = data['interview__id'].count()\n",
    "mean_value1 = data[score_name1].mean()\n",
    "mean_value2 = data[score_name2].mean()\n",
    "print(f\" Total UNITS: {total_unit}, with an average of lower anomalies in selected items {mean_value1} and upper one {mean_value2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T00:20:12.276919Z",
     "start_time": "2023-08-27T00:20:11.977101Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.groupby(['interview__id','responsible']).agg({score_name1: 'mean', score_name2:'mean'})\n",
    "data = data.reset_index()\n",
    "\n",
    "resp_df = {}\n",
    "for resp in data['responsible'].unique():\n",
    "    mask = (data['responsible']==resp)\n",
    "\n",
    "    total_unit = data[mask]['interview__id'].count()\n",
    "    mean_value1 = data[mask][score_name1].mean()\n",
    "    mean_value2 = data[mask][score_name2].mean()\n",
    "    resp_df[resp] = [mean_value1, mean_value2]\n",
    "    print(f\"{resp} - Total UNITS: {total_unit}, with an average of lower anomalies in selected items {mean_value1} and upper one {mean_value2}\")\n",
    "\n",
    "resp_df = pd.DataFrame.from_records(resp_df).T\n",
    "resp_df = resp_df.reset_index()\n",
    "resp_df.columns = ['responsible', 'mean_value1', 'mean_value2']\n",
    "resp_df.set_index('responsible')['mean_value1'].plot(kind='bar')\n",
    "plt.title(score_name1)\n",
    "plt.show()\n",
    "resp_df.set_index('responsible')['mean_value2'].plot(kind='bar')\n",
    "plt.title(score_name2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlss",
   "language": "python",
   "name": "mlss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
