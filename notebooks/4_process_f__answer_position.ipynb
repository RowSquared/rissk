{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T14:35:59.155675Z",
     "start_time": "2023-08-27T14:35:59.127966Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T14:35:59.704296Z",
     "start_time": "2023-08-27T14:35:59.156032Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.import_utils import *\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from src.feature_processing import *\n",
    "from src.item_processing import  *\n",
    "from src.utils.stats_utils import *\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T14:35:59.966781Z",
     "start_time": "2023-08-27T14:35:59.704950Z"
    }
   },
   "outputs": [],
   "source": [
    "with initialize(config_path='../configuration', version_base='1.1'):\n",
    "    config = compose(config_name='main.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T14:36:19.574527Z",
     "start_time": "2023-08-27T14:35:59.967051Z"
    }
   },
   "outputs": [],
   "source": [
    "features_class = ItemFeatureProcessing(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T14:36:22.551496Z",
     "start_time": "2023-08-27T14:36:19.572215Z"
    }
   },
   "outputs": [],
   "source": [
    "df_item = features_class.df_item\n",
    "self = features_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Answer Position ITEM Level Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T14:36:22.648202Z",
     "start_time": "2023-08-27T14:36:22.548983Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_name = 'f__answer_position'\n",
    "score_name = 's__answer_position'\n",
    "df = df_item[~pd.isnull(df_item[feature_name])].copy()\n",
    "# Select only those variables that have at least three distinct values and more than one hundred records\n",
    "\n",
    "variables =  self.filter_variable_name_by_frequency(df, feature_name, frequency=100, min_unique_values=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Plot the Relative Position of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_range in range(0, len(variables), 50):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.boxplot(df[df['variable_name'].isin(variables[index_range:index_range+50])],x='variable_name', y=feature_name)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Calculate the entropy for each variable_name per responsible, i.e., one entropy value for each responsible and variable_name.\n",
    "2. Entropy is calculated only for those varible_name of each responsible that have at least 10 times the number of possible values of the variable_name\n",
    "3. Mark as \"anomalous\" any entropy value that is lower than the 50% of the median entropy value\n",
    "4. Plot the entropy value for each variable name by responsible and colour in red those values that have very low entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variables:\n",
    "\n",
    "    mask = (df['variable_name']==var) \n",
    "    unique_values = df[mask][feature_name].nunique()\n",
    "    entropy_df = df[mask].groupby('responsible')[feature_name].apply(calculate_entropy,unique_values=unique_values, min_record_sample=5).copy()\n",
    "    entropy_df = entropy_df.reset_index()\n",
    "    entropy_df = entropy_df[~pd.isnull(entropy_df[feature_name])]\n",
    "    \n",
    "    if entropy_df.shape[0] > 0:\n",
    "        entropy_df.sort_values(feature_name, inplace=True, ascending=False)\n",
    "\n",
    "        median_value = entropy_df[feature_name].median()\n",
    "        entropy_df[score_name] = entropy_df[feature_name].apply(lambda x: 1 if x< median_value-50/100*median_value else 0)\n",
    "\n",
    "        anomaly_df = entropy_df[entropy_df[score_name] == 1]\n",
    "        no_anomaly_df = entropy_df[entropy_df[score_name] == 0]\n",
    "        plt.bar(no_anomaly_df['responsible'], no_anomaly_df[feature_name], color='blue', label='No Anomaly')\n",
    "        plt.bar(anomaly_df['responsible'], anomaly_df[feature_name], color='red', label='Anomaly')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(var)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variables:\n",
    "    mask = (df['variable_name']==var)\n",
    "    unique_values = df[mask][feature_name].nunique()\n",
    "    entropy_df = df[mask].groupby('responsible')[feature_name].apply(calculate_entropy,unique_values=unique_values)\n",
    "    entropy_df = entropy_df.reset_index()\n",
    "    entropy_df = entropy_df[~pd.isnull(entropy_df[feature_name])]\n",
    "    \n",
    "    if entropy_df.shape[0] > 0:\n",
    "        entropy_df.sort_values(feature_name, inplace=True, ascending=False)\n",
    "\n",
    "        median_value = entropy_df[feature_name].median()\n",
    "\n",
    "        median_value = entropy_df[feature_name].median()\n",
    "        entropy_df[score_name] = entropy_df[feature_name].apply(lambda x: 1 if x < median_value - 50/100 * median_value else 0)\n",
    "        df.loc[mask,score_name] = df[mask]['responsible'].map(entropy_df.set_index('responsible')[score_name])\n",
    "    # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Answer Position Responsible Level Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T23:17:05.168238Z",
     "start_time": "2023-08-26T23:17:04.973017Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.groupby(['responsible','variable_name']).agg({score_name: 'mean', feature_name:'count'})\n",
    "data = data.reset_index()\n",
    "entropy_ = data.groupby('responsible')[score_name].mean()\n",
    "entropy_.plot(kind='bar')\n",
    "plt.title('entropy__answer_position')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlss",
   "language": "python",
   "name": "mlss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
