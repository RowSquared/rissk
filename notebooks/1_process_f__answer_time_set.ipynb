{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:29.596427Z",
     "start_time": "2023-08-26T17:04:29.073502Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.import_utils import *\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from src.unit_proccessing import  *\n",
    "from src.utils.stats_utils import *\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyod.models.ecod import ECOD\n",
    "from pythresh.thresholds.hist import HIST\n",
    "from pythresh.thresholds.hist import HIST\n",
    "from pythresh.thresholds.filter import FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:29.835024Z",
     "start_time": "2023-08-26T17:04:29.596942Z"
    }
   },
   "outputs": [],
   "source": [
    "with initialize(config_path='../configuration', version_base='1.1'):\n",
    "    config = compose(config_name='main.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:49.354888Z",
     "start_time": "2023-08-26T17:04:29.835879Z"
    }
   },
   "outputs": [],
   "source": [
    "features_class = UnitDataProcessing(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Answer Time Set ITEM Level Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Get Feature and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:52.452223Z",
     "start_time": "2023-08-26T17:04:49.383723Z"
    }
   },
   "outputs": [],
   "source": [
    "df_item = features_class.df_item\n",
    "df_unit = features_class.df_unit\n",
    "feature_name = 'f__answer_time_set'\n",
    "score_name = 's__answer_time_set'\n",
    "df = df_item[~pd.isnull(df_item[feature_name])].copy()\n",
    "df[feature_name] = df[feature_name].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:52.556438Z",
     "start_time": "2023-08-26T17:04:52.453261Z"
    }
   },
   "outputs": [],
   "source": [
    "df[feature_name].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:52.648423Z",
     "start_time": "2023-08-26T17:04:52.559375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column that has the hours mapped to order of frequency\n",
    "sorted_hours = df[feature_name].value_counts().index\n",
    "hour_to_rank = {hour: rank for rank, hour in enumerate(sorted_hours)}\n",
    "# Sorting the DataFrame based on the 'frequency' column in descending order\n",
    "df['frequency'] = df[feature_name].map(hour_to_rank)\n",
    "df['frequency'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### FIND and Plot Anomalies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:52.822828Z",
     "start_time": "2023-08-26T17:04:52.649346Z"
    }
   },
   "outputs": [],
   "source": [
    "#ECOD algorithm makes use of cumulative function and is non-parametric for detecting anomalies in answer time set.\n",
    "# SET the contamintation parameter to 0.11. IT seems from different observations on distinct surveys to be a good threshold. Alternatively. you can use the FILTER function to define the optimal contamination parameter.\n",
    "#  Carefully as using FILTER it hangs for a while \n",
    "model = ECOD(contamination=0.11)#contamination=FILTER(method='medfilt', random_state=42)\n",
    "model.fit(df[['frequency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:52.870136Z",
     "start_time": "2023-08-26T17:04:52.822976Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find Anomalies\n",
    "df[score_name] = model.predict(df[['frequency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:52.870415Z",
     "start_time": "2023-08-26T17:04:52.863367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the number and percentage of anomalies \n",
    "df[score_name].value_counts(), df[score_name].value_counts()/df[score_name].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:52.940594Z",
     "start_time": "2023-08-26T17:04:52.866914Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df[score_name]==0]['frequency'].min(), df[df[score_name]==0]['frequency'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:52.996983Z",
     "start_time": "2023-08-26T17:04:52.942264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set to zero \"High frequency\" anomalies as they should not be ocnsidered as such\n",
    "df.loc[df['frequency']<=df[df[score_name]==0]['frequency'].min(),score_name] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:53.128199Z",
     "start_time": "2023-08-26T17:04:52.980179Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.histogram_bin_edges(df[feature_name], bins=48)\n",
    "data_true = df[df[score_name]==0][feature_name]\n",
    "data_false = df[df[score_name]==1][feature_name]\n",
    "\n",
    "plt.hist(data_true, bins=bins, alpha=0.5, color='blue', label='True')\n",
    "plt.hist(data_false, bins=bins, alpha=0.5, color='red', label='False')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Answer Time Set UNIT Level Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:04:53.251041Z",
     "start_time": "2023-08-26T17:04:53.136301Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.groupby(['interview__id'])[score_name].sum() / df.groupby(['interview__id'])[score_name].count()\n",
    "data = data.reset_index()\n",
    "data[score_name].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T16:41:37.552392Z",
     "start_time": "2023-08-26T16:41:37.539024Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "total_anomalies  = data[data[score_name]>0]['interview__id'].count()\n",
    "total_unit = data['interview__id'].count()\n",
    "perc = round(total_anomalies/total_unit,2)\n",
    "print(f\"UNITS with anomalies: {total_anomalies} of {total_unit}, ({perc}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T16:51:15.657868Z",
     "start_time": "2023-08-26T16:51:15.477938Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.groupby(['interview__id','responsible'])[score_name].sum() / df.groupby(['interview__id','responsible'])[score_name].count()\n",
    "data = data.reset_index()\n",
    "\n",
    "resp_perc = {}\n",
    "for resp in data['responsible'].unique():\n",
    "    mask = (data['responsible']==resp)\n",
    "    total_anomalies  = data[(data[score_name]>0)&mask]['interview__id'].count()\n",
    "    total_unit = data[mask]['interview__id'].count()\n",
    "    perc = round(total_anomalies/total_unit,2)\n",
    "    resp_perc[resp] = [perc]\n",
    "    print(f\"{resp} - UNITS with anomalies: {total_anomalies} of {total_unit}, ({perc}%)\")\n",
    "\n",
    "resp_perc = pd.DataFrame.from_records(resp_perc).T\n",
    "resp_perc = resp_perc.reset_index()\n",
    "resp_perc.columns = ['responsible', 'perc']\n",
    "resp_perc.set_index('responsible')['perc'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Visually check if it keeps on working by shifting the time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tz in range(24):\n",
    "    # Get the feature shifted\n",
    "    df = df_item[~pd.isnull(df_item[feature_name])].copy()\n",
    "    df[feature_name] = df[feature_name].astype(float)\n",
    "    df[feature_name] = df[feature_name].apply(lambda x: (x-tz)%24).astype(float)\n",
    "    # Create Frequency column with feature shifted\n",
    "    sorted_hours = df[feature_name].value_counts().index\n",
    "    hour_to_rank = {hour: rank for rank, hour in enumerate(sorted_hours)}\n",
    "    # Sorting the DataFrame based on the 'frequency' column in descending order\n",
    "    df['frequency'] = df[feature_name].map(hour_to_rank)\n",
    "\n",
    "    # Train and find anomalies\n",
    "    model = ECOD(contamination=0.11)#contamination=FILTER(method='savgol', random_state=42, sigma=30))#FILTER\n",
    "    model.fit(df[['frequency']])\n",
    "    df[score_name] = model.predict(df[['frequency']])\n",
    "    df.loc[df['frequency']<=df[df[score_name]==0]['frequency'].min(),score_name] =0\n",
    "\n",
    "    # Plot the anomalies for each time shift\n",
    "    bins = np.histogram_bin_edges(df[feature_name], bins=48)\n",
    "    data_true = df[df[score_name]==0][feature_name]\n",
    "    data_false = df[df[score_name]==1][feature_name]\n",
    "    plt.hist(data_true, bins=bins, alpha=0.5, color='blue', label='True')\n",
    "    plt.hist(data_false, bins=bins, alpha=0.5, color='red', label='False')\n",
    "    plt.title(\"Time shift +{}\".format(str(tz)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlss",
   "language": "python",
   "name": "mlss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
